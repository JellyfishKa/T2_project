## Получение токенов

1) Заходим в .env.example и заполняем все поля (HF-Token, если планируем использовать приватную модель)

2) Запускаем config.py

3) Проверяем, что все работает, для этого раскоментируйте код в файле config.py:


## Создание базового класса LLM_Client

1) Создан интерфейс клиента LLM-модели

2) Добавлены базовые тесты к написанному интерфейсу (тесты ветки main в данный момент не работают корректно, нужно закоментировать тесты для конкретных клиентов)

