# Бенчмарк LLM моделей

Скрипт для тестирования и сравнения производительности всех 3 LLM моделей:
- GigaChat3-10B-A1.8B
- Cotype-Nano
- T-Pro-it-1.0

## Метрики

Бенчмарк собирает следующие метрики для каждой модели:

1. **response_time_ms** - Среднее время ответа в миллисекундах
2. **quality_score** - Оценка качества ответа (0-100)
   - Длина ответа (20 баллов)
   - Наличие ключевых слов (30 баллов)
   - Структурированность (15 баллов)
   - Отсутствие ошибок (15 баллов)
   - Релевантность (20 баллов)
3. **success_rate** - Процент успешных ответов
4. **cost_rub** - Общая стоимость в рублях (если применимо)

## Тестовые данные

Бенчмарк использует реалистичные тестовые данные с 8 магазинами в Москве:

- Магазин Центральный (Красная площадь)
- Магазин Арбат
- Магазин Тверская
- Магазин Парк Культуры
- Магазин Сокольники
- Магазин Измайлово
- Магазин ВДНХ
- Магазин Останкино

### Типы задач

1. **route_planning** - Планирование маршрута между магазинами
2. **store_info** - Информация о магазинах в районе
3. **logistics** - Планирование доставки с минимальным пробегом
4. **analysis** - Анализ покрытия сети магазинов
5. **optimization** - Оптимизация размещения новых магазинов

## Использование

### Базовый запуск

```bash
python ml/benchmarks/llm_benchmark.py
```

### С параметрами

```bash
# Указать количество итераций
python ml/benchmarks/llm_benchmark.py --iterations 10

# Использовать mock режим (без загрузки моделей, для тестирования)
python ml/benchmarks/llm_benchmark.py --mock

# Комбинация параметров
python ml/benchmarks/llm_benchmark.py --iterations 3 --mock
```

### Через скрипты запуска (опционально)

**Linux/Mac/Server:**
```bash
python ml/benchmarks/llm_benchmark.py
python ml/benchmarks/llm_benchmark.py --iterations 3
python ml/benchmarks/llm_benchmark.py --mock
```

**Windows (локальная разработка):**
```cmd
ml\benchmarks\run_benchmark.bat
ml\benchmarks\run_benchmark.bat --iterations 3
ml\benchmarks\run_benchmark.bat --mock
```

## Результаты

Результаты сохраняются в `ml/benchmarks/results.json` в следующем формате:

```json
{
  "timestamp": "2026-01-16T16:33:46.375000",
  "num_iterations": 1,
  "test_data_count": 5,
  "models": {
    "gigachat": {
      "model_name": "ai-sage/GigaChat3-10B-A1.8B",
      "model_id": "gigachat",
      "use_mock": true,
      "iterations": [...],
      "metrics": {
        "response_time_ms": 0.01,
        "quality_score": 74.27,
        "success_rate": 100.0,
        "cost_rub": 0.0000,
        "total_tests": 5,
        "successful_tests": 5
      }
    },
    ...
  }
}
```

## Логи

Детальные логи сохраняются в `ml/benchmarks/benchmark.log`

## Время выполнения

- **Mock режим**: ~1-5 секунд на итерацию
- **Реальный режим**: 10-30 минут на 5 итераций (зависит от модели и оборудования)

## Обработка ошибок

- Если модель недоступна, автоматически используется mock режим
- Ошибки логируются, но не прерывают выполнение бенчмарка
- Каждая модель тестируется независимо

## Примечания

- Для реального тестирования требуется загруженные модели (см. `ml/test_models.py`)
- Mock режим полезен для тестирования логики бенчмарка без загрузки моделей
- Стоимость рассчитывается приблизительно и может отличаться от реальных тарифов API
